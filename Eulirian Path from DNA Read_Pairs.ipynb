{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffb67b7",
   "metadata": {},
   "source": [
    "#### In order to generate a Eulirian Path from DNA Read Pairs, an artificial Eulirian Cycle will  be created first. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64811ddc",
   "metadata": {},
   "source": [
    "## Eulirian Cycle Concept And Application for Sequencing DNA from Read_Pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43788da1",
   "metadata": {},
   "source": [
    "In a directed and balanced graph, read_pairs are the imaginary edges and their prefixes & suffixes are nodes,\n",
    "submitted in a dict as keys and values, respectively. An example of read_pairs is  (TAA,GCC) where comma indicates a \n",
    "specific distance between reads/kmers. The nodes (prefixes & suffixes) that are derived from this read_pair edge are :\n",
    "                                                \n",
    "                                                (TA,GC)->(AA,CC)\n",
    "\n",
    "\n",
    "All edges must be entered once.\n",
    "Each time a value of a dict is entered, an edge is used, since the value is called from a the dict's key.\n",
    "As mentioned above, the key along with the value constitutes the kmer, which is an edge.\n",
    "        \n",
    "1) First, select randomly a) a kmer , b) (one of) that kmer's value(s).\n",
    "Append the kmer and its value to a list. \n",
    "From now on, only append chosen values through next steps. Do not append keys.\n",
    "           \n",
    "2) Move to another vertex by using that value as dict key and calling (one of) it value(s). Repeat the process.\n",
    "Save the first dict key with more than one outdegrees (efferent edges) a potential new start node that might be used later on. \n",
    "\n",
    "3) When another vertex is not accessible anymore, that is, the last value used corresponds to a dict key that \n",
    "has been emptied, a cycle has been completed. Check if all values have been appended to the list, that is, check if eulirian cycle has been completed (while condition). \n",
    "           \n",
    "4) If cycle is not complete (not Eulirian), transform the list with the appended values according to this :\n",
    "        \n",
    "    start node,2nd node,3rd node,potential exit node, 5th node,6th node, 7th node\n",
    "                                                   ||\n",
    "                                                   \\/\n",
    "  potential exit node, 5th node,6th node, 7th node, ~~startnode~~ ,2nd node,3rd node,potential exit node.\n",
    "           \n",
    "This method is valid since incomplete cycles in directed & balanced graphs end up solely at starting points. \n",
    "Hence, the last node (7th) leads back to the starting node. For this reason, all nodes(vertices) starting from\n",
    "the potential exit node up to the last node can be inserted at the start of the list. This way, a new cycle is\n",
    "created, where the potential exit node has now become the new start node AND the last node(so far).\n",
    "The potential exit node has still unused efferents (outdegrees) and therefore helps to continue searching for \n",
    "a Eulirian Cycle. \n",
    "           \n",
    "Be aware of the ~~start node~~. The start node, that is the very first dict value, acts as dict key\n",
    "and keys shouldn't exist anywhere else except for the start of the cycle. Yet, one more transformation\n",
    "will PUSH it forward and render it inside the cycle. Hence, the previous start node must NOT be \n",
    "incorporated in a new cycle during the transformation of the latter. However, a new start node always exists,\n",
    "since the new transformed cycle will start with a new node which represents a dict key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bada33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eulirian_Path (adjacency_dic):\n",
    "    \"\"\" Input : Dic with tuple as key (2 kmers' prefixes) and LIST that contain tuple(s) (same kmers' suffixes) as value.\n",
    "                This is the output of DeBruinj_for_Read_Pairs(). For a better conceptualization of nodes, please refer to\n",
    "                the description of DeBruijn_for_Read_Pairs.\n",
    "                \n",
    "        Output: list with int or str as elements. Elements in list indicate nodes and must be as many as the input's dict values() \n",
    "                + 1 element that is inserted at the start to indicate a key (start) node in contrast to the rest which are all dict values.\n",
    "                                                                                                                        \n",
    "                From a graph (input), checks whether a Eulirian Path exists. If so, a Eulirian cycle is first created by joining the\n",
    "                edges (extreme nodes and NOT graph edges) of the graph. Then, the Eulirian Path is found by rotating the final Eulirian Cycle accordingly\n",
    " \n",
    "    \n",
    "                                                                                                                        \"\"\"\n",
    "    import random\n",
    "    from collections import deque\n",
    "    \n",
    "    N_of_nodes   = sum (list(map(lambda x: len(x), adjacency_dic.values())))             # dict values are lists, thus measure the elements inside them (nodes). x is the list and len(x) the number of its elements which are tuples           \n",
    "    first_key,last_key = Eulirian_Edges_for_Read_Pairs (adjacency_dic)                   # These should be the final first and last nodes\n",
    "    adjacency_dic = Path_With_Joined_Edges_for_Read_Pairs (adjacency_dic,first_key,last_key) # Create an artificial cycle by joining first and last node\n",
    "    cycle        = deque([first_key, adjacency_dic[first_key].pop()])                    # first dict value element is accessed via first key, first edge is used.\n",
    "    exit         = 0                                                                     # distance of first exit node after a cycle, from the end of the next cycle \n",
    "    start_key    = cycle[0]                                                              # the only element of cycle that represents key instead of value. Always in start.\n",
    "      \n",
    "    while len(cycle) != N_of_nodes +1 :                                                  #+1 because Eulirian cycle's length = a start key node in start + dict values' elements \n",
    "        current_node = cycle[-1]                                                         \n",
    "\n",
    "        if len(adjacency_dic[current_node]) > 1 and exit == 0 :                          # at least two elements in dic value (list) and no exit node found yet. exit == 0 to prevent from changing exit_nodes when new ones are entered\n",
    "            exit_node = cycle[-1]                                                        ## only the first exit node is needed in every new cycle for wayout\n",
    "        \n",
    "        if adjacency_dic[current_node] != [] :                                           # at least one element in dic value(list)\n",
    "            current_node = adjacency_dic[current_node].pop()                             \n",
    "            cycle.append(current_node)\n",
    "            try:\n",
    "                exit_node\n",
    "                exit +=1                                                                # first exit node's distance from end of cycle increases with new elements\n",
    "            except:                                                                     # without an exit node present, don't measure distance yet\n",
    "                pass      \n",
    "\n",
    "        else :                                                                          #dead-end, no value left for this node\n",
    "            cycle.remove(start_key)                                                     #remove the start key from cycle. This will also facilitate rotating exit node to the start instead of end of cycle\n",
    "            cycle.rotate(exit)                                                          #move exit node to the start of the cycle and maintain elements' sequence\n",
    "            cycle.append (cycle[0])                                                     #append the exit node at the end of the cycle to complete a cycle and continue from there\n",
    "            start_key = cycle[0]                                                        #save the start key for the next dead-end\n",
    "            exit = 0                                                                    #exit=0 so that we can find the first exit node and save it                                                               \n",
    "    \n",
    "    while cycle[-1] != last_key:                                                        #as long as the last key is not at last position\n",
    "        cycle.rotate(-cycle.index(first_key))                                           #move all the nodes to the left until a first key occurence is at first place\n",
    "  \n",
    "    return cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eulirian_Edges_for_Read_Pairs (adjacency_dic):\n",
    "    \"\"\"Input : Dic with tuple as key (kmers' prefixes) and LIST that contain tuple(s) (same kmers' suffixes) as value.\n",
    "       Output :list with two tuples. Each tuple contains two str elements. \n",
    "       The first tuple corresponds to the first node (based on read_pairs) of a Eulirian Path.\n",
    "       The second tuple corresponds to the last node (based on read_pairs) of a Eulirian Path.\n",
    "       \n",
    "       Checks whether a Eulirian path exists (2 unbalanced nodes and a graph which is connected). If so, finds the endpoint nodes.\n",
    "       Note that an 'edge' here indicates that these nodes are at the endpoints of the path. Thus, it doesn't indicate graph edges\"\"\"\n",
    "    \n",
    "    \n",
    "    outdegrees_indegrees_sum = dict.fromkeys(adjacency_dic, 0)\n",
    "    more_afferents = []                                                   # nodes with more indegrees than outdegrees\n",
    "    more_efferents = []                                                   # nodes with more outdegrees than outdegrees\n",
    "    \n",
    "    \n",
    "    for key, values in adjacency_dic.items():                              \n",
    "        outdegrees_indegrees_sum[key] += len(values)                      # add N of outdegrees for each key-node\n",
    "        \n",
    "    for key,values in adjacency_dic.items():                               \n",
    "        for node in values:\n",
    "            try :\n",
    "                outdegrees_indegrees_sum[node] -= 1                       # remove 1 every time a node is an indegree\n",
    "            except:\n",
    "                outdegrees_indegrees_sum[node] = -1                       #create artificial node\n",
    "\n",
    "    for key,value in outdegrees_indegrees_sum.items():            \n",
    "        if value > 0:\n",
    "            more_efferents.append([key,value])                            # append tuple and value to a list - > [('',''),value]\n",
    "        if value < 0:\n",
    "            more_afferents.append([key,value])\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "            \n",
    "    if len(more_efferents)==1 and len(more_afferents) == 1  :              #2 unbalanced node condition for Eulirian Path. len == 1 when only one list has been appended\n",
    "            if abs (more_efferents[0][1]) == abs (more_afferents[0][1]) :  #if the values are equal \n",
    "                return [more_efferents[0][0],more_afferents[0][0]]         #return the keys/nodes      \n",
    "    \n",
    "    else :\n",
    "        print('There are not 2 almost balanced edges that can support Eulirian Path afterwards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc941087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Path_With_Joined_Edges_for_Read_Pairs (adjacency_dic, first_key, last_key):\n",
    "    \"\"\"Input 1: Dic with tuple as key (kmers' prefixes) and LIST that contain tuple(s) as value (same kmers' suffixes).\n",
    "                The key and its value(s) are adjacent nodes/vertices that together form a read_pair\n",
    "       Input 2: tuple with 2 str elements. The tuple corresponds to the first node (based on read_pairs) of a Eulirian Path.\n",
    "       Input 3: tuple with 2 str elements. The tuple corresponds to the last node  (based on read_pairs) of a Eulirian Path.\n",
    "       Output : Dic with tuple as key (kmers' prefixes) and LIST that contain tuple(s) (same kmers' suffixes) as values. \n",
    "                The key and its value(s) [tuple or tuples with kmers/reads] are adjacent nodes that together form a read_pair.\n",
    "       \n",
    "       In a dictionary from which a Eulirian Path can be formed, join the first and last unbalanced node to create a Eulirian cycle \"\"\"\n",
    "        \n",
    "    if last_key in adjacency_dic.keys():\n",
    "        adjacency_dic[last_key].append(first_key)\n",
    "    else:\n",
    "        adjacency_dic[last_key] = [first_key]\n",
    "        \n",
    "    return adjacency_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28402c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeBruijn_for_Read_Pairs (read_pairs):\n",
    "    \"\"\"Input : list with tuples that contain (k,d)-mers. That is a pair of kmers of length k and distance d between them.\n",
    "       Output : Dic with tuple as key (kmers' prefixes) and LIST that contain tuple(s) (same kmers' suffixes) as values.\n",
    "       \n",
    "       For each read_pair, create a tuple with the prefixes of its reads and a value with the suffixes of its reads.\n",
    "       Read_pairs are (k,d)-mers like this : \n",
    "                                               TAA|GCC  \n",
    "       \n",
    "       The symbol | indicates distance and replaces an unknown base. It would be || for distance = 2 and so on.\n",
    "       The symbol | is for illustrative reasons. Regardless the distance, the latter is merely indicated by the \",\" of the input tuples) \n",
    "       The prefixes of a read_pair's reads are read1[:-1] & read2[:-1] and the suffixes are read1[1:] and read2[1:].\n",
    "       Hence, the read_pair TAA|GCC has (TA,GC) as a prefix and (AA,CC) as a suffix.\n",
    "       If a read_pair appears multiple times, append a tuple with its suffixes as value for an equal number of times.\n",
    "       For instance, if there are two  TAA|GCC  in the input, the respective part of output will be : \n",
    "                                \n",
    "                                (TA,GC)-> [(AA,CC),(AA,CC)]\n",
    "                                      \n",
    "                                    or, equivalently\n",
    "                \n",
    "                            dic[(TA,GC)]-> [(AA,CC),(AA,CC)]\n",
    "       \n",
    "       Note that when the read_pairs can form a Eulirian path, each key/vertex/node is not only a pair of suffixes of a read_pair \n",
    "       but also a pair of prefixes of another key (apart from start & end in RIGHT sequence). \n",
    "       DeBruijn's output can be used to 'glue' read_pairs afterwards. \"\"\"\n",
    "    \n",
    "    adjacency_dic = {}\n",
    "    \n",
    "    for pair in read_pairs:                                   # pair's type is list, elements are tuples that contain str\n",
    "        prefixes = (pair[0][:-1],pair[1][:-1])\n",
    "        suffixes = (pair[0][1:],pair[1][1:])\n",
    "        \n",
    "        if prefixes not in adjacency_dic:\n",
    "            adjacency_dic[prefixes] = []\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        adjacency_dic[prefixes].append(suffixes)\n",
    "    \n",
    "    return adjacency_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Pair_Path_to_Genome (read_pairs):\n",
    "    \"\"\"Input : list with tuples that constitute read_pairs of this form : (ACC,GCC). \n",
    "               The first element of tuple is the suffix and the second the prefix. Kmers are separated by a distance d which is \n",
    "               occupied by an unknown base. Think of the \",\" in (ACC,GCC) as a space with unknown bases between ACC and GCC.\n",
    "       Output: list with 2 strings that corresponds to the final paths of suffices and prefices, respectively.\n",
    "       \n",
    "       An already PROPERLY arranged sequence of read_pairs is submitted as input and the final genome for suffixes and prefixes is created.\"\"\"\n",
    "    \n",
    "    suffices = []\n",
    "    prefices = []\n",
    "    \n",
    "    for pair in read_pairs:\n",
    "        suffices.append(pair[0])\n",
    "        prefices.append(pair[1])\n",
    "        \n",
    "    sfx_path = suffices.pop(0)\n",
    "    for sfx in range(len(suffices)):\n",
    "        sfx_path += suffices[sfx][-1]\n",
    "        \n",
    "    prfx_path = prefices.pop(0)\n",
    "    for prfx in range(len(prefices)):\n",
    "        prfx_path += prefices[prfx][-1]\n",
    "        \n",
    "    return [sfx_path,prfx_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Overlap_in_Read_Pairs (suffix_path, prefix_path,kmer_length,distance):\n",
    "    \"\"\"Input 1: string\n",
    "       Input 2: string\n",
    "       Input 3: int indicating the length of one read(kmer) in read_pairs before the paths were created\n",
    "       Input 4: int indicating the distance between read_pairs before the paths were created\n",
    "       Output : False or nothing\n",
    "       \n",
    "       From an upper path of kmers and a lower path of kmers derived from a graph comprising nodes withupper and lower kmers, \n",
    "       checks whether the overlapping characters are identical.\n",
    "       For instance, for paths created by (2,1)mers with length 2 and distance 1:\n",
    "                        \n",
    "                        upper path -> A G C A G C T G C T \n",
    "                        lower path ->       A G C T G C T G C A\n",
    "                        \n",
    "      The overlapping characters are identical, thus nothing will be returned. Otherwise, False would be returned. \"\"\"\n",
    "    \n",
    "    comparable_sfx_path = suffix_path[kmer_length+distance:]\n",
    "    comparable_prfx_path= prefix_path[:len(prefix_path) - (kmer_length+distance) ]\n",
    "    \n",
    "    for index in range(len(comparable_prfx_path)):\n",
    "        if comparable_sfx_path[index] == prefix_path[index]:\n",
    "            pass\n",
    "        else :\n",
    "            return False\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406484ad",
   "metadata": {},
   "source": [
    "###### assemble final path from upper and lower path derived from read_pairs\n",
    "(upper and lower paths are Eulirian Paths derived from the same nodes. Each DeBruijn node is contains two kmers/reads which are prefixes of a read pair and suffixes of another (except the 2 endpoint nodes, unless these endpoints have been artificially joined to form a Eulirian Cycle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Putting it all together\n",
    "\n",
    "kmer_length = x\n",
    "distance    = y\n",
    "\n",
    "debruijn_graph = DeBruijn_for_Read_Pairs(some_reads_of_yours)\n",
    "path = Eulirian_Path(debruijn_graph)                                                # Path WITH nodes containing BOTH prefixes and suffixes is created here\n",
    "suffix_path, prefix_path = Read_Pair_Path_to_Genome(path)                           # Prefixes and suffixes are separated and a path without nodes is created for each\n",
    "\n",
    "if Overlap_in_Read_Pairs(suffix_path,prefix_path,kmer_length,distance) != False:    #A final path might be created without corresponding to a real path\n",
    "                                                                                    ## To make sure that the final path corresponds to a real one, \n",
    "                                                                                    ### an identical match of overlapping bases must exist. Like below\n",
    "    \n",
    "    final_path = suffix_path+prefix_path[len(suffix_path)-(kmer_length+distance):]  #Assemble final path upper path -> A G C A G C T G C T \n",
    "                                                                                                        #lower path ->        A G C T G C T G C A\n",
    "                                                                                                     #final path ->  A G C A G C T G C T G C A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331f52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
